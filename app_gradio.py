import os
import gradio as gr
import clueai
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration
tokenizer = T5Tokenizer.from_pretrained("ClueAI/ChatYuan-large-v2")
model = T5ForConditionalGeneration.from_pretrained("ClueAI/ChatYuan-large-v2")
# è¯¥åŠ è½½æ–¹å¼ï¼Œåœ¨æœ€å¤§é•¿åº¦ä¸º512æ—¶ å¤§çº¦éœ€è¦6Gå¤šæ˜¾å­˜
# å¦‚æ˜¾å­˜ä¸å¤Ÿï¼Œå¯é‡‡ç”¨ä»¥ä¸‹æ–¹å¼åŠ è½½ï¼Œè¿›ä¸€æ­¥å‡å°‘æ˜¾å­˜éœ€æ±‚ï¼Œçº¦ä¸º3Gï¼Œä½†æ˜¯è¯·æ³¨æ„æ‚¨çš„æ˜¾å¡æ˜¯å¦æ”¯æŒæ­¤ç§æ¨ç†æ–¹å¼
# model = T5ForConditionalGeneration.from_pretrained("ClueAI/ChatYuan-large-v2").half()
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

def preprocess(text):
  text = text.replace("\n", "\\n").replace("\t", "\\t")
  return text

def postprocess(text):
  return text.replace("\\n", "\n").replace("\\t", "\t").replace('%20','  ')#.replace(" ", "&nbsp;")


generate_config = {'do_sample': True, 'top_p': 0.9, 'top_k': 50, 'temperature': 0.7, 
                   'num_beams': 1, 'max_length': 1024, 'min_length': 3, 'no_repeat_ngram_size': 5, 
                   'length_penalty': 0.6, 'return_dict_in_generate': True, 'output_scores': True}
def answer(text, sample=True, top_p=0.9, temperature=0.7):
  '''sampleï¼šæ˜¯å¦æŠ½æ ·ã€‚ç”Ÿæˆä»»åŠ¡ï¼Œå¯ä»¥è®¾ç½®ä¸ºTrue;
  top_pï¼š0-1ä¹‹é—´ï¼Œç”Ÿæˆçš„å†…å®¹è¶Šå¤šæ ·'''
  text = preprocess(text)
  encoding = tokenizer(text=[text], truncation=True, padding=True, max_length=1024, return_tensors="pt").to(device) 
  if not sample:
      out = model.generate(**encoding, return_dict_in_generate=True, output_scores=False, max_new_tokens=1024, num_beams=1, length_penalty=0.6)
  else:
      out = model.generate(**encoding, return_dict_in_generate=True, output_scores=False, max_new_tokens=1024, do_sample=True, top_p=top_p, temperature=temperature, no_repeat_ngram_size=6)
  #out=model.generate(**encoding, **generate_config)
  out_text = tokenizer.batch_decode(out["sequences"], skip_special_tokens=True)
  return postprocess(out_text[0])

def clear_session():
    return '', None

def chatyuan_bot(input, history):
    history = history or []
    if len(history) > 5:
       history = history[-5:]

    context = "\n".join([f"ç”¨æˆ·ï¼š{input_text}\nå°å…ƒï¼š{answer_text}" for input_text, answer_text in history])
    print(context)

    input_text = context + "\nç”¨æˆ·ï¼š" + input + "\nå°å…ƒï¼š"
    output_text = answer(input_text)
    history.append((input, output_text))
    print(history)
    return history, history

block = gr.Blocks()

with block as demo:
    gr.Markdown("""<h1><center>å…ƒè¯­æ™ºèƒ½â€”â€”ChatYuan</center></h1>
        <font size=4>å›ç­”æ¥è‡ªChatYuan, æ˜¯æ¨¡å‹ç”Ÿæˆçš„ç»“æœ, è¯·è°¨æ…è¾¨åˆ«å’Œå‚è€ƒ, ä¸ä»£è¡¨ä»»ä½•äººè§‚ç‚¹ | Answer generated by ChatYuan model</font>
    """)
    chatbot = gr.Chatbot(label='ChatYuan')
    message = gr.Textbox()
    state = gr.State()
    message.submit(chatyuan_bot, inputs=[message, state], outputs=[chatbot, state])
    with gr.Row():
      clear_history = gr.Button("ğŸ‘‹ æ¸…é™¤å†å²å¯¹è¯ | Clear")
      clear = gr.Button('ğŸ§¹ æ¸…é™¤å‘é€æ¡† | Clear Input')
      send = gr.Button("ğŸš€ å‘é€ | Send")
      
    send.click(chatyuan_bot, inputs=[message, state], outputs=[chatbot, state])
    clear.click(lambda: None, None, message, queue=False)
    clear_history.click(fn=clear_session , inputs=[], outputs=[chatbot, state], queue=False)
    

def ChatYuan(api_key, text_prompt):

    cl = clueai.Client(api_key,
                        check_api_key=True)
    # generate a prediction for a prompt
    # éœ€è¦è¿”å›å¾—åˆ†çš„è¯ï¼ŒæŒ‡å®šreturn_likelihoods="GENERATION"
    prediction = cl.generate(model_name='ChatYuan-large', prompt=text_prompt)
    # print the predicted text
    print('prediction: {}'.format(prediction.generations[0].text))
    response = prediction.generations[0].text
    if response == '':
        response = "å¾ˆæŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜"

    return response
  
def chatyuan_bot_api(api_key, input, history):
    history = history or []

    if len(history) > 5:
      history = history[-5:]

    context = "\n".join([f"ç”¨æˆ·ï¼š{input_text}\nå°å…ƒï¼š{answer_text}" for input_text, answer_text in history])
    print(context)

    input_text = context + "\nç”¨æˆ·ï¼š" + input + "\nå°å…ƒï¼š"
    output_text = ChatYuan(api_key, input_text)
    history.append((input, output_text))
    print(history)
    return history, history

block = gr.Blocks()

with block as demo_1:
    gr.Markdown("""<h1><center>å…ƒè¯­æ™ºèƒ½â€”â€”ChatYuan</center></h1>
    <font size=4>å›ç­”æ¥è‡ªChatYuan, ä»¥ä¸Šæ˜¯æ¨¡å‹ç”Ÿæˆçš„ç»“æœ, è¯·è°¨æ…è¾¨åˆ«å’Œå‚è€ƒ, ä¸ä»£è¡¨ä»»ä½•äººè§‚ç‚¹  | Answer generated by ChatYuan model</font>
    
    <font size=4>åœ¨ä½¿ç”¨æ­¤åŠŸèƒ½å‰ï¼Œä½ éœ€è¦æœ‰ä¸ªAPI key. API key å¯ä»¥é€šè¿‡è¿™ä¸ª<a href='https://www.clueai.cn/' target="_blank">å¹³å°</a>è·å–</font>
    """)
    api_key = gr.inputs.Textbox(label="è¯·è¾“å…¥ä½ çš„api-key(å¿…å¡«)", default="", type='password')
    chatbot = gr.Chatbot(label='ChatYuan')
    message = gr.Textbox()
    state = gr.State()
    message.submit(chatyuan_bot_api, inputs=[api_key,message, state], outputs=[chatbot, state])
    with gr.Row():
      clear_history = gr.Button("ğŸ‘‹ æ¸…é™¤å†å²å¯¹è¯ | Clear Context")
      clear = gr.Button('ğŸ§¹ æ¸…é™¤å‘é€æ¡† | Clear Input')
      send = gr.Button("ğŸš€ å‘é€ | Send")

    send.click(chatyuan_bot_api, inputs=[api_key,message, state], outputs=[chatbot, state])
    clear.click(lambda: None, None, message, queue=False)
    clear_history.click(fn=clear_session , inputs=[], outputs=[chatbot, state], queue=False)

block = gr.Blocks()
with block as introduction:
    gr.Markdown("""<h1><center>å…ƒè¯­æ™ºèƒ½â€”â€”ChatYuan</center></h1>
    
<font size=4>ğŸ˜‰ChatYuan: å…ƒè¯­åŠŸèƒ½å‹å¯¹è¯å¤§æ¨¡å‹ | General Model for Dialogue with ChatYuan
<br>
ğŸ‘ChatYuan-large-v2æ˜¯ä¸€ä¸ªæ”¯æŒä¸­è‹±åŒè¯­çš„åŠŸèƒ½å‹å¯¹è¯è¯­è¨€å¤§æ¨¡å‹ï¼Œæ˜¯ç»§ChatYuanç³»åˆ—ä¸­ChatYuan-large-v1å¼€æºåçš„åˆä¸€ä¸ªå¼€æºæ¨¡å‹ã€‚ChatYuan-large-v2ä½¿ç”¨äº†å’Œ v1ç‰ˆæœ¬ç›¸åŒçš„æŠ€æœ¯æ–¹æ¡ˆï¼Œåœ¨å¾®è°ƒæ•°æ®ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ã€æ€ç»´é“¾ç­‰æ–¹é¢è¿›è¡Œäº†ä¼˜åŒ–ã€‚
<br>
ChatYuan large v2 is an open-source large language model for dialogue, supports both Chinese and English languages, and in ChatGPT style.
<br>
ChatYuan-large-v2æ˜¯ChatYuanç³»åˆ—ä¸­ä»¥è½»é‡åŒ–å®ç°é«˜è´¨é‡æ•ˆæœçš„æ¨¡å‹ä¹‹ä¸€ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§æ˜¾å¡ã€ PCç”šè‡³æ‰‹æœºä¸Šè¿›è¡Œæ¨ç†ï¼ˆINT4 æœ€ä½åªéœ€ 400M ï¼‰ã€‚
<br>
åœ¨Chatyuan-large-v1çš„åŸæœ‰åŠŸèƒ½çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬ç»™æ¨¡å‹è¿›è¡Œäº†å¦‚ä¸‹ä¼˜åŒ–ï¼š
- æ–°å¢äº†ä¸­è‹±åŒè¯­å¯¹è¯èƒ½åŠ›ã€‚
- æ–°å¢äº†æ‹’ç­”èƒ½åŠ›ã€‚å¯¹äºä¸€äº›å±é™©ã€æœ‰å®³çš„é—®é¢˜ï¼Œå­¦ä¼šäº†æ‹’ç­”å¤„ç†ã€‚
- æ–°å¢äº†ä»£ç ç”ŸæˆåŠŸèƒ½ã€‚å¯¹äºåŸºç¡€ä»£ç ç”Ÿæˆè¿›è¡Œäº†ä¸€å®šç¨‹åº¦ä¼˜åŒ–ã€‚
- å¢å¼ºäº†åŸºç¡€èƒ½åŠ›ã€‚åŸæœ‰ä¸Šä¸‹æ–‡é—®ç­”ã€åˆ›æ„æ€§å†™ä½œèƒ½åŠ›æ˜æ˜¾æå‡ã€‚
- æ–°å¢äº†è¡¨æ ¼ç”ŸæˆåŠŸèƒ½ã€‚ä½¿ç”Ÿæˆçš„è¡¨æ ¼å†…å®¹å’Œæ ¼å¼æ›´é€‚é…ã€‚
- å¢å¼ºäº†åŸºç¡€æ•°å­¦è¿ç®—èƒ½åŠ›ã€‚
- æœ€å¤§é•¿åº¦tokenæ•°æ‰©å±•åˆ°4096ã€‚
- å¢å¼ºäº†æ¨¡æ‹Ÿæƒ…æ™¯èƒ½åŠ›ã€‚.<br>
<br>
Based on the original functions of Chatyuan-large-v1, we optimized the model as follows:
-Added the ability to speak in both Chinese and English.
-Added the ability to refuse to answer. Learn to refuse to answer some dangerous and harmful questions.
-Added code generation functionality. Basic code generation has been optimized to a certain extent.
-Enhanced basic capabilities. The original contextual Q&A and creative writing skills have significantly improved.
-Added a table generation function. Make the generated table content and format more appropriate.
-Enhanced basic mathematical computing capabilities.
-The maximum number of length tokens has been expanded to 4096.
-Enhanced ability to simulate scenarios< br>
<br>
ğŸ‘€<a href='https://www.cluebenchmarks.com/clueai.html'>PromptCLUE-large</a>åœ¨1000äº¿tokenä¸­æ–‡è¯­æ–™ä¸Šé¢„è®­ç»ƒ, ç´¯è®¡å­¦ä¹ 1.5ä¸‡äº¿ä¸­æ–‡token, å¹¶ä¸”åœ¨æ•°ç™¾ç§ä»»åŠ¡ä¸Šè¿›è¡ŒPromptä»»åŠ¡å¼è®­ç»ƒ. é’ˆå¯¹ç†è§£ç±»ä»»åŠ¡, å¦‚åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æŠ½å–ç­‰, å¯ä»¥è‡ªå®šä¹‰æ ‡ç­¾ä½“ç³»; é’ˆå¯¹å¤šç§ç”Ÿæˆä»»åŠ¡, å¯ä»¥è¿›è¡Œé‡‡æ ·è‡ªç”±ç”Ÿæˆ.  <br> 
<br>
 &nbsp; <a href='https://modelscope.cn/models/ClueAI/ChatYuan-large/summary' target="_blank">ModelScope</a> &nbsp; | &nbsp; <a href='https://huggingface.co/ClueAI/ChatYuan-large-v1' target="_blank">Huggingface</a> &nbsp; | &nbsp; <a href='https://www.clueai.cn' target="_blank">å®˜ç½‘ä½“éªŒåœº</a> &nbsp; | &nbsp; <a href='https://github.com/clue-ai/clueai-python#ChatYuan%E5%8A%9F%E8%83%BD%E5%AF%B9%E8%AF%9D' target="_blank">ChatYuan-API</a> &nbsp; | &nbsp; <a href='https://github.com/clue-ai/ChatYuan' target="_blank">Githubé¡¹ç›®åœ°å€</a> &nbsp; | &nbsp; <a href='https://openi.pcl.ac.cn/ChatYuan/ChatYuan/src/branch/main/Fine_tuning_ChatYuan_large_with_pCLUE.ipynb' target="_blank">OpenIå…è´¹è¯•ç”¨</a> &nbsp;
</font>
<a href="https://clustrmaps.com/site/1bts0"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=ycVCe17noTYFDs30w7AmkFaE-TwabMBukDP1802_Lts&cl=ffffff" /></a>
    """)


gui = gr.TabbedInterface(interface_list=[introduction,demo, demo_1], tab_names=["ç›¸å…³ä»‹ç»","å¼€æºæ¨¡å‹", "APIè°ƒç”¨"])
gui.launch(quiet=True,show_api=False, share = False)
